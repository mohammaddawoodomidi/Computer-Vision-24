{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:03<00:00, 1.78MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.48 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.47  Python-3.12.6 torch-2.5.1+cpu CPU (Intel Core(TM) i7-4510U 2.00GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=dataset/data.yaml, epochs=1, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\davoo\\OneDrive\\Desktop\\Computer Vision\\Project\\Computer-Vision-24\\Project\\dataset\\labels\\train... 280 images, 7 backgrounds, 0 corrupt: 100%|██████████| 280/280 [00:04<00:00, 65.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\davoo\\OneDrive\\Desktop\\Computer Vision\\Project\\Computer-Vision-24\\Project\\dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\davoo\\OneDrive\\Desktop\\Computer Vision\\Project\\Computer-Vision-24\\Project\\dataset\\labels\\valid... 80 images, 1 backgrounds, 0 corrupt: 100%|██████████| 80/80 [00:01<00:00, 57.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\davoo\\OneDrive\\Desktop\\Computer Vision\\Project\\Computer-Vision-24\\Project\\dataset\\labels\\valid.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      2.608      3.366      2.537         39        640: 100%|██████████| 18/18 [08:10<00:00, 27.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:22<00:45, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:48<00:00, 16.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232    0.00385      0.388    0.00942    0.00299\n",
      "\n",
      "1 epochs completed in 0.155 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics 8.3.47  Python-3.12.6 torch-2.5.1+cpu CPU (Intel Core(TM) i7-4510U 2.00GHz)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:25<00:51, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:56<00:28, 28.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [01:11<00:00, 23.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232    0.00303      0.129       0.01    0.00311\n",
      "Speed: 4.1ms preprocess, 603.6ms inference, 0.0ms loss, 132.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Training metrics are not available for plotting.\n",
      "Training complete. Best model saved at chair_detection/yolov8_chair/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 290.0ms\n",
      "Speed: 2.5ms preprocess, 290.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   2%|▎         | 1/40 [00:01<00:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 280.3ms\n",
      "Speed: 4.6ms preprocess, 280.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   5%|▌         | 2/40 [00:01<00:34,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 203.8ms\n",
      "Speed: 0.0ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   8%|▊         | 3/40 [00:02<00:29,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 222.5ms\n",
      "Speed: 12.3ms preprocess, 222.5ms inference, 10.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  10%|█         | 4/40 [00:03<00:28,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 204.9ms\n",
      "Speed: 0.0ms preprocess, 204.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  12%|█▎        | 5/40 [00:03<00:26,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 193.4ms\n",
      "Speed: 4.4ms preprocess, 193.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  15%|█▌        | 6/40 [00:04<00:24,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 281.0ms\n",
      "Speed: 10.2ms preprocess, 281.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  18%|█▊        | 7/40 [00:05<00:24,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 227.9ms\n",
      "Speed: 10.0ms preprocess, 227.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  20%|██        | 8/40 [00:06<00:24,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 216.3ms\n",
      "Speed: 4.5ms preprocess, 216.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  22%|██▎       | 9/40 [00:06<00:23,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  25%|██▌       | 10/40 [00:07<00:23,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 219.7ms\n",
      "Speed: 10.0ms preprocess, 219.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  28%|██▊       | 11/40 [00:08<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 231.5ms\n",
      "Speed: 4.0ms preprocess, 231.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  30%|███       | 12/40 [00:09<00:21,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 214.7ms\n",
      "Speed: 0.0ms preprocess, 214.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  32%|███▎      | 13/40 [00:10<00:20,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 300.1ms\n",
      "Speed: 0.0ms preprocess, 300.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  35%|███▌      | 14/40 [00:10<00:20,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 214.0ms\n",
      "Speed: 5.9ms preprocess, 214.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  38%|███▊      | 15/40 [00:11<00:18,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 267.9ms\n",
      "Speed: 12.9ms preprocess, 267.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  40%|████      | 16/40 [00:12<00:18,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 191.0ms\n",
      "Speed: 13.3ms preprocess, 191.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  42%|████▎     | 17/40 [00:13<00:16,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 185.0ms\n",
      "Speed: 6.0ms preprocess, 185.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  45%|████▌     | 18/40 [00:13<00:15,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 270.1ms\n",
      "Speed: 3.5ms preprocess, 270.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  48%|████▊     | 19/40 [00:14<00:15,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 223.8ms\n",
      "Speed: 9.9ms preprocess, 223.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  50%|█████     | 20/40 [00:15<00:14,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 331.4ms\n",
      "Speed: 6.7ms preprocess, 331.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  52%|█████▎    | 21/40 [00:16<00:15,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 209.7ms\n",
      "Speed: 5.0ms preprocess, 209.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  55%|█████▌    | 22/40 [00:16<00:14,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 300.0ms\n",
      "Speed: 5.1ms preprocess, 300.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  57%|█████▊    | 23/40 [00:17<00:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 212.3ms\n",
      "Speed: 4.0ms preprocess, 212.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  60%|██████    | 24/40 [00:18<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 240.4ms\n",
      "Speed: 7.0ms preprocess, 240.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  62%|██████▎   | 25/40 [00:19<00:12,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 202.8ms\n",
      "Speed: 4.0ms preprocess, 202.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  65%|██████▌   | 26/40 [00:20<00:10,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 216.1ms\n",
      "Speed: 5.6ms preprocess, 216.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  68%|██████▊   | 27/40 [00:20<00:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 385.0ms\n",
      "Speed: 10.1ms preprocess, 385.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  70%|███████   | 28/40 [00:21<00:10,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 219.8ms\n",
      "Speed: 10.5ms preprocess, 219.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  72%|███████▎  | 29/40 [00:22<00:09,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 231.8ms\n",
      "Speed: 6.3ms preprocess, 231.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  75%|███████▌  | 30/40 [00:23<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 223.1ms\n",
      "Speed: 11.5ms preprocess, 223.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  78%|███████▊  | 31/40 [00:24<00:07,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 194.0ms\n",
      "Speed: 0.0ms preprocess, 194.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  80%|████████  | 32/40 [00:24<00:06,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 205.8ms\n",
      "Speed: 4.0ms preprocess, 205.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  82%|████████▎ | 33/40 [00:25<00:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 271.9ms\n",
      "Speed: 9.7ms preprocess, 271.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  85%|████████▌ | 34/40 [00:26<00:04,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 194.6ms\n",
      "Speed: 10.8ms preprocess, 194.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  88%|████████▊ | 35/40 [00:27<00:03,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 254.8ms\n",
      "Speed: 5.0ms preprocess, 254.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  90%|█████████ | 36/40 [00:27<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 199.9ms\n",
      "Speed: 9.0ms preprocess, 199.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  92%|█████████▎| 37/40 [00:28<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 195.4ms\n",
      "Speed: 4.3ms preprocess, 195.4ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  95%|█████████▌| 38/40 [00:29<00:01,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 222.2ms\n",
      "Speed: 4.0ms preprocess, 222.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  98%|█████████▊| 39/40 [00:30<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 203.0ms\n",
      "Speed: 10.2ms preprocess, 203.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 40/40 [00:30<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to detected\\results_summary.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 314.2ms\n",
      "Speed: 12.1ms preprocess, 314.2ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   2%|▎         | 1/40 [00:01<00:42,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 219.6ms\n",
      "Speed: 0.0ms preprocess, 219.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   5%|▌         | 2/40 [00:01<00:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 277.0ms\n",
      "Speed: 6.0ms preprocess, 277.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   8%|▊         | 3/40 [00:02<00:35,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 173.2ms\n",
      "Speed: 10.0ms preprocess, 173.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  10%|█         | 4/40 [00:03<00:32,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 206.7ms\n",
      "Speed: 10.0ms preprocess, 206.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  12%|█▎        | 5/40 [00:04<00:31,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 199.9ms\n",
      "Speed: 4.1ms preprocess, 199.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  15%|█▌        | 6/40 [00:05<00:29,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 245.2ms\n",
      "Speed: 4.5ms preprocess, 245.2ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  18%|█▊        | 7/40 [00:06<00:29,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 274.5ms\n",
      "Speed: 7.8ms preprocess, 274.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  20%|██        | 8/40 [00:07<00:29,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 205.6ms\n",
      "Speed: 9.8ms preprocess, 205.6ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  22%|██▎       | 9/40 [00:08<00:27,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 192.0ms\n",
      "Speed: 5.1ms preprocess, 192.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  25%|██▌       | 10/40 [00:09<00:26,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 200.3ms\n",
      "Speed: 5.0ms preprocess, 200.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  28%|██▊       | 11/40 [00:09<00:25,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 194.4ms\n",
      "Speed: 10.3ms preprocess, 194.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  30%|███       | 12/40 [00:10<00:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 194.9ms\n",
      "Speed: 9.9ms preprocess, 194.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  32%|███▎      | 13/40 [00:11<00:23,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 194.3ms\n",
      "Speed: 4.5ms preprocess, 194.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  35%|███▌      | 14/40 [00:12<00:21,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 263.0ms\n",
      "Speed: 0.0ms preprocess, 263.0ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  38%|███▊      | 15/40 [00:13<00:21,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 246.1ms\n",
      "Speed: 10.5ms preprocess, 246.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  40%|████      | 16/40 [00:14<00:21,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 234.1ms\n",
      "Speed: 5.0ms preprocess, 234.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  42%|████▎     | 17/40 [00:15<00:20,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 204.5ms\n",
      "Speed: 8.1ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  45%|████▌     | 18/40 [00:15<00:19,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 195.1ms\n",
      "Speed: 0.0ms preprocess, 195.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  48%|████▊     | 19/40 [00:16<00:18,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 315.6ms\n",
      "Speed: 5.0ms preprocess, 315.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  50%|█████     | 20/40 [00:17<00:17,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 312.5ms\n",
      "Speed: 8.3ms preprocess, 312.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  52%|█████▎    | 21/40 [00:18<00:18,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 180.0ms\n",
      "Speed: 6.5ms preprocess, 180.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  55%|█████▌    | 22/40 [00:19<00:16,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 430.8ms\n",
      "Speed: 0.0ms preprocess, 430.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  57%|█████▊    | 23/40 [00:20<00:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 196.1ms\n",
      "Speed: 3.9ms preprocess, 196.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  60%|██████    | 24/40 [00:21<00:14,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 230.0ms\n",
      "Speed: 4.0ms preprocess, 230.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  62%|██████▎   | 25/40 [00:22<00:13,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 247.7ms\n",
      "Speed: 0.0ms preprocess, 247.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  65%|██████▌   | 26/40 [00:23<00:12,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 242.6ms\n",
      "Speed: 7.6ms preprocess, 242.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  68%|██████▊   | 27/40 [00:24<00:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 210.1ms\n",
      "Speed: 0.0ms preprocess, 210.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  70%|███████   | 28/40 [00:25<00:10,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 330.0ms\n",
      "Speed: 9.8ms preprocess, 330.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  72%|███████▎  | 29/40 [00:26<00:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 216.3ms\n",
      "Speed: 5.1ms preprocess, 216.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  75%|███████▌  | 30/40 [00:27<00:09,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 190.1ms\n",
      "Speed: 0.0ms preprocess, 190.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  78%|███████▊  | 31/40 [00:27<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 199.8ms\n",
      "Speed: 9.0ms preprocess, 199.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  80%|████████  | 32/40 [00:28<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 200.3ms\n",
      "Speed: 1.0ms preprocess, 200.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  82%|████████▎ | 33/40 [00:29<00:06,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 239.5ms\n",
      "Speed: 5.7ms preprocess, 239.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  85%|████████▌ | 34/40 [00:30<00:05,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 897.5ms\n",
      "Speed: 6.1ms preprocess, 897.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  88%|████████▊ | 35/40 [00:32<00:05,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 408.5ms\n",
      "Speed: 11.6ms preprocess, 408.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  90%|█████████ | 36/40 [00:33<00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 416.8ms\n",
      "Speed: 5.5ms preprocess, 416.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  92%|█████████▎| 37/40 [00:34<00:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 482.3ms\n",
      "Speed: 8.0ms preprocess, 482.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  95%|█████████▌| 38/40 [00:35<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 401.3ms\n",
      "Speed: 6.0ms preprocess, 401.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  98%|█████████▊| 39/40 [00:37<00:01,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 370.1ms\n",
      "Speed: 9.9ms preprocess, 370.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection: 100%|██████████| 40/40 [00:38<00:00,  1.05it/s]\n",
      "Creating Video:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 312.3ms\n",
      "Speed: 10.3ms preprocess, 312.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:   2%|▎         | 1/40 [00:00<00:33,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 268.8ms\n",
      "Speed: 13.7ms preprocess, 268.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:   5%|▌         | 2/40 [00:01<00:29,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 329.4ms\n",
      "Speed: 0.0ms preprocess, 329.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:   8%|▊         | 3/40 [00:02<00:27,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 459.0ms\n",
      "Speed: 5.0ms preprocess, 459.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  10%|█         | 4/40 [00:03<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 408.1ms\n",
      "Speed: 0.0ms preprocess, 408.1ms inference, 8.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  12%|█▎        | 5/40 [00:04<00:31,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 320.0ms\n",
      "Speed: 10.4ms preprocess, 320.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  15%|█▌        | 6/40 [00:05<00:29,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 370.6ms\n",
      "Speed: 7.2ms preprocess, 370.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  18%|█▊        | 7/40 [00:05<00:28,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 406.8ms\n",
      "Speed: 6.0ms preprocess, 406.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  20%|██        | 8/40 [00:06<00:28,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 322.6ms\n",
      "Speed: 2.0ms preprocess, 322.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  22%|██▎       | 9/40 [00:07<00:26,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 373.3ms\n",
      "Speed: 9.9ms preprocess, 373.3ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  25%|██▌       | 10/40 [00:08<00:26,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 376.0ms\n",
      "Speed: 6.6ms preprocess, 376.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  28%|██▊       | 11/40 [00:09<00:27,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 306.5ms\n",
      "Speed: 5.0ms preprocess, 306.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  30%|███       | 12/40 [00:10<00:25,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 395.8ms\n",
      "Speed: 10.3ms preprocess, 395.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  32%|███▎      | 13/40 [00:11<00:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 428.3ms\n",
      "Speed: 9.7ms preprocess, 428.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  35%|███▌      | 14/40 [00:12<00:25,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 374.6ms\n",
      "Speed: 10.1ms preprocess, 374.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  38%|███▊      | 15/40 [00:13<00:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 405.4ms\n",
      "Speed: 6.0ms preprocess, 405.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  40%|████      | 16/40 [00:14<00:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 644.2ms\n",
      "Speed: 5.0ms preprocess, 644.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  42%|████▎     | 17/40 [00:15<00:25,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 312.1ms\n",
      "Speed: 8.0ms preprocess, 312.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  45%|████▌     | 18/40 [00:16<00:21,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 567.6ms\n",
      "Speed: 43.5ms preprocess, 567.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  48%|████▊     | 19/40 [00:18<00:23,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 319.8ms\n",
      "Speed: 9.1ms preprocess, 319.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  50%|█████     | 20/40 [00:18<00:20,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 742.3ms\n",
      "Speed: 8.3ms preprocess, 742.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  52%|█████▎    | 21/40 [00:20<00:20,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 368.0ms\n",
      "Speed: 1.6ms preprocess, 368.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  55%|█████▌    | 22/40 [00:21<00:19,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 790.6ms\n",
      "Speed: 8.0ms preprocess, 790.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  57%|█████▊    | 23/40 [00:22<00:20,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 549.1ms\n",
      "Speed: 7.0ms preprocess, 549.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  60%|██████    | 24/40 [00:23<00:19,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 420.7ms\n",
      "Speed: 5.0ms preprocess, 420.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  62%|██████▎   | 25/40 [00:25<00:18,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 375.1ms\n",
      "Speed: 8.0ms preprocess, 375.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  65%|██████▌   | 26/40 [00:26<00:16,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 363.1ms\n",
      "Speed: 9.0ms preprocess, 363.1ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  68%|██████▊   | 27/40 [00:26<00:13,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 437.1ms\n",
      "Speed: 6.0ms preprocess, 437.1ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  70%|███████   | 28/40 [00:27<00:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 671.9ms\n",
      "Speed: 8.0ms preprocess, 671.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  72%|███████▎  | 29/40 [00:28<00:11,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 324.6ms\n",
      "Speed: 3.6ms preprocess, 324.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  75%|███████▌  | 30/40 [00:29<00:09,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 400.5ms\n",
      "Speed: 7.8ms preprocess, 400.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  78%|███████▊  | 31/40 [00:30<00:08,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 506.2ms\n",
      "Speed: 7.5ms preprocess, 506.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  80%|████████  | 32/40 [00:31<00:07,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 396.4ms\n",
      "Speed: 10.0ms preprocess, 396.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  82%|████████▎ | 33/40 [00:32<00:06,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 321.6ms\n",
      "Speed: 10.1ms preprocess, 321.6ms inference, 10.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  85%|████████▌ | 34/40 [00:33<00:05,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 358.0ms\n",
      "Speed: 9.3ms preprocess, 358.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  88%|████████▊ | 35/40 [00:34<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 350.0ms\n",
      "Speed: 8.4ms preprocess, 350.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  90%|█████████ | 36/40 [00:35<00:04,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 424.6ms\n",
      "Speed: 0.0ms preprocess, 424.6ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  92%|█████████▎| 37/40 [00:36<00:02,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 439.4ms\n",
      "Speed: 8.0ms preprocess, 439.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  95%|█████████▌| 38/40 [00:37<00:02,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 331.6ms\n",
      "Speed: 0.0ms preprocess, 331.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  98%|█████████▊| 39/40 [00:38<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 401.0ms\n",
      "Speed: 10.9ms preprocess, 401.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video: 100%|██████████| 40/40 [00:39<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at detections_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Ensure Dataset Path Exists\n",
    "dataset_path = \"dataset/data.yaml\"  # Update with your dataset path\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset YAML file not found: {dataset_path}\")\n",
    "\n",
    "# Load Pretrained YOLOv8 Model\n",
    "model = YOLO('yolov8n.pt')  # Use 'yolov8n.pt', 'yolov8s.pt', etc., based on your hardware capacity\n",
    "\n",
    "# Train the Model\n",
    "results = model.train(\n",
    "    data=dataset_path,       # Path to dataset YAML\n",
    "    epochs=20,                # Number of epochs\n",
    "    batch=16,                # Batch size\n",
    "    imgsz=640,               # Image size\n",
    "    workers=4,               # Number of data loading workers\n",
    "    optimizer='AdamW',       # Optimizer\n",
    "    lr0=0.001,               # Initial learning rate\n",
    "    patience=10,             # Early stopping\n",
    "    augment=True,            # Data augmentation\n",
    "    val=True                 # Validate after each epoch\n",
    ")\n",
    "\n",
    "# Plot Training Loss\n",
    "if hasattr(results, 'metrics'):\n",
    "    metrics = results.metrics\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(metrics.get('box_loss', []), label=\"Box Loss\")\n",
    "    plt.plot(metrics.get('obj_loss', []), label=\"Object Loss\")\n",
    "    plt.plot(metrics.get('cls_loss', []), label=\"Classification Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Training metrics are not available for plotting.\")\n",
    "\n",
    "# Save the Best Model\n",
    "best_model_path = 'chair_detection/yolov8_chair/weights/best.pt'\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "model.save(best_model_path)\n",
    "print(f\"Training complete. Best model saved at {best_model_path}\")\n",
    "\n",
    "# Load Trained Model\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# Function to Detect and Count Objects\n",
    "def detect_and_count(image, model, class_name=\"chair\"):\n",
    "    results = model(image)  # Run detection\n",
    "    detections = results[0].boxes  # Extract bounding boxes\n",
    "    chair_count = 0\n",
    "\n",
    "    # Process each detection\n",
    "    for detection in detections:\n",
    "        class_id = int(detection.cls)  # Class ID\n",
    "        if model.names[class_id] == class_name:  # Match the target class\n",
    "            chair_count += 1\n",
    "            # Draw bounding box and label\n",
    "            x1, y1, x2, y2 = map(int, detection.xyxy[0])  # Bounding box coordinates\n",
    "            conf = detection.conf  # Confidence score\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                f\"{class_name} {conf:.2f}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "            )\n",
    "    return image, chair_count\n",
    "\n",
    "# Process Images and Save Results\n",
    "def process_images(input_dir, output_dir, model, class_name=\"chair\"):\n",
    "    results_summary = []\n",
    "    supported_formats = (\".jpg\", \".png\", \".jpeg\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in tqdm(os.listdir(input_dir), desc=\"Processing images\"):\n",
    "        if not img_file.endswith(supported_formats):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        try:\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(\"Invalid image format or file.\")\n",
    "\n",
    "            annotated_image, count = detect_and_count(image, model, class_name)\n",
    "            output_path = os.path.join(output_dir, img_file)\n",
    "            cv2.imwrite(output_path, annotated_image)\n",
    "            results_summary.append({\"image\": img_file, \"chair_count\": count})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "    summary_path = os.path.join(output_dir, \"results_summary.json\")\n",
    "    with open(summary_path, \"w\") as json_file:\n",
    "        json.dump(results_summary, json_file, indent=4)\n",
    "\n",
    "    print(f\"Processing complete. Results saved to {summary_path}\")\n",
    "\n",
    "# Live Detection Display\n",
    "def live_detection(input_dir, model, class_name=\"chair\"):\n",
    "    supported_formats = (\".jpg\", \".png\", \".jpeg\")\n",
    "    window_name = \"Live Detection Results\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, 800, 600)\n",
    "\n",
    "    for img_file in tqdm(os.listdir(input_dir), desc=\"Live Detection\"):\n",
    "        if not img_file.endswith(supported_formats):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        try:\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(\"Invalid image format or file.\")\n",
    "\n",
    "            annotated_image, count = detect_and_count(image, model, class_name)\n",
    "            cv2.imshow(window_name, annotated_image)\n",
    "            if cv2.waitKey(500) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Save Detections as Video\n",
    "def save_detection_video(input_dir, output_video_path, model, class_name=\"chair\"):\n",
    "    supported_formats = (\".jpg\", \".png\", \".jpeg\")\n",
    "    frame_rate = 10  # Adjust frame rate as needed\n",
    "\n",
    "    # Validate input images\n",
    "    valid_images = [\n",
    "        os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(supported_formats)\n",
    "    ]\n",
    "    if not valid_images:\n",
    "        raise ValueError(\"No valid image files found in the directory.\")\n",
    "\n",
    "    # Determine frame size\n",
    "    first_frame = cv2.imread(valid_images[0])\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    # Define video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    for img_file in tqdm(valid_images, desc=\"Creating Video\"):\n",
    "        try:\n",
    "            image = cv2.imread(img_file)\n",
    "            annotated_image, count = detect_and_count(image, model, class_name)\n",
    "            video_writer.write(annotated_image)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "    video_writer.release()\n",
    "    print(f\"Video saved at {output_video_path}\")\n",
    "\n",
    "# Input and Output Directories\n",
    "INPUT_IMAGES_DIR = \"dataset/images/test\"  # Replace with your image directory\n",
    "OUTPUT_IMAGES_DIR = \"detected\"  # Replace with output directory\n",
    "os.makedirs(OUTPUT_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Process and Save Annotated Images\n",
    "process_images(INPUT_IMAGES_DIR, OUTPUT_IMAGES_DIR, model)\n",
    "\n",
    "# Live Detection Display\n",
    "live_detection(INPUT_IMAGES_DIR, model)\n",
    "\n",
    "# Save Detection Results as Video\n",
    "save_detection_video(INPUT_IMAGES_DIR, \"detections_output.mp4\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
