{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and train YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define paths (ensure these are correct paths)\n",
    "data_yaml_path = \"Augmented_Dataset/data.yaml\"  # Path to your data.yaml file\n",
    "output_dir = \"train_results\"  # Directory to save outputs\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Model parameters\n",
    "TARGET_CLASS = \"chair\"\n",
    "\n",
    "# Load the YOLOv8 model for training\n",
    "model = YOLO('yolov8n.pt')  # You can use 'yolov8s.pt' or 'yolov8m.pt' for larger models\n",
    "\n",
    "\n",
    "# Load class names from data.yaml\n",
    "with open(data_yaml_path, 'r') as file:\n",
    "    data_yaml = yaml.safe_load(file)  # Load the content of the YAML file\n",
    "class_names = data_yaml['names']  # This should give you a list of class names, e.g., ['chair']\n",
    "\n",
    "# Training the model on your custom dataset\n",
    "# The 'data' argument now uses the 'data.yaml' file for paths and class names\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    project=output_dir,\n",
    "    save=True,\n",
    "    verbose=True,\n",
    "    epochs=100,               # Number of training epochs\n",
    "    batch=8,                 # Batch size\n",
    "    imgsz=1280,                # Image size\n",
    "    lr0=1e-4,                 # Initial learning rate\n",
    "    lrf=0.1,                  # Final learning rate\n",
    "    optimizer=\"SGD\",          # Optimizer\n",
    "    weight_decay=0.00005,      # Regularization\n",
    "    momentum=0.937,            # Momentum for SGD\n",
    "    patience=20,               # Reduce patience\n",
    "    freeze=5,                 # Freeze backbone layers\n",
    "    mosaic=0.5,                 # Reduced mosaic due to small dataset\n",
    "\n",
    ")\n",
    "\n",
    "print(f\"Detection results saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the best model on unseen images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def setup_logging(log_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Set up logging configuration\n",
    "    \n",
    "    Args:\n",
    "        log_dir (str): Directory to save log files\n",
    "    \"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO, \n",
    "        format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "        filename=os.path.join(log_dir, 'chair_detection.log')\n",
    "    )\n",
    "\n",
    "def create_output_directories(base_dir: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create structured output directories\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Base directory for outputs\n",
    "    \n",
    "    Returns:\n",
    "        Dict of directory paths\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_root = f\"chair_detection_outputs_{timestamp}\"\n",
    "    \n",
    "    dirs = {\n",
    "        'root': output_root,\n",
    "        'logs': os.path.join(output_root, 'logs'),\n",
    "        'predictions': os.path.join(output_root, 'predictions'),\n",
    "        'annotated_images': os.path.join(output_root, 'annotated_images'),\n",
    "        'detection_results': os.path.join(output_root, 'detection_results')\n",
    "    }\n",
    "    \n",
    "    # Create all directories\n",
    "    for dir_path in dirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    return dirs\n",
    "\n",
    "def load_model_configuration(data_yaml_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load and validate model configuration\n",
    "    \n",
    "    Args:\n",
    "        data_yaml_path (str): Path to data configuration file\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing model configuration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(data_yaml_path, 'r') as file:\n",
    "            data_yaml = yaml.safe_load(file)\n",
    "        \n",
    "        # Validate critical configurations\n",
    "        assert 'names' in data_yaml, \"Invalid YAML: Missing class names\"\n",
    "        \n",
    "        # Validate target class exists\n",
    "        target_class = \"chair\"\n",
    "        assert target_class in data_yaml['names'], f\"Target class '{target_class}' not in dataset\"\n",
    "        \n",
    "        return {\n",
    "            'data_yaml': data_yaml,\n",
    "            'class_names': data_yaml['names'],\n",
    "            'target_class': target_class\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Configuration loading error: {e}\")\n",
    "        raise\n",
    "\n",
    "def detect_chairs(\n",
    "    model_path: str, \n",
    "    source: str, \n",
    "    output_dirs: Dict[str, str],\n",
    "    data_yaml_path: str,\n",
    "    conf_threshold: float = 0.25, \n",
    "    iou_threshold: float = 0.45\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Detect and count chairs in images or video\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load model\n",
    "        model = YOLO(model_path)\n",
    "        \n",
    "        # Load class names\n",
    "        with open(data_yaml_path, 'r') as file:\n",
    "            data_yaml = yaml.safe_load(file)\n",
    "        \n",
    "        class_names = data_yaml['names']\n",
    "        target_class_index = class_names.index(\"chair\")\n",
    "        \n",
    "        # Check if source is a video\n",
    "        is_video = source.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))\n",
    "        \n",
    "        if is_video:\n",
    "            # Open video\n",
    "            input_video = cv2.VideoCapture(source)\n",
    "            \n",
    "            # Verify video is opened\n",
    "            if not input_video.isOpened():\n",
    "                print(f\"ERROR: Cannot open video {source}\")\n",
    "                return []\n",
    "            \n",
    "            # Get video properties\n",
    "            frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = input_video.get(cv2.CAP_PROP_FPS)\n",
    "            \n",
    "            # Detailed video property logging\n",
    "            print(f\"Video Properties:\")\n",
    "            print(f\"Width: {frame_width}\")\n",
    "            print(f\"Height: {frame_height}\")\n",
    "            print(f\"FPS: {fps}\")\n",
    "            \n",
    "            # Precise video writer setup\n",
    "            output_video_path = os.path.join(output_dirs['annotated_images'], 'chairs_detected.mp4')\n",
    "            \n",
    "            # Try different codecs\n",
    "            codecs = ['mp4v', 'XVID', 'avc1']\n",
    "            video_writer = None\n",
    "            \n",
    "            for codec in codecs:\n",
    "                try:\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*codec)\n",
    "                    video_writer = cv2.VideoWriter(\n",
    "                        output_video_path, \n",
    "                        fourcc, \n",
    "                        fps, \n",
    "                        (frame_width, frame_height)\n",
    "                    )\n",
    "                    \n",
    "                    if video_writer.isOpened():\n",
    "                        print(f\"Successfully created video writer with {codec} codec\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed with {codec} codec: {e}\")\n",
    "            \n",
    "            if video_writer is None:\n",
    "                print(\"ERROR: Could not create video writer\")\n",
    "                return []\n",
    "            \n",
    "            processed_results = []\n",
    "            frame_count = 0\n",
    "            \n",
    "            while True:\n",
    "                ret, frame = input_video.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame_count += 1\n",
    "                \n",
    "                # Perform detection\n",
    "                results = model(frame, conf=conf_threshold, iou=iou_threshold)\n",
    "                \n",
    "                # Count chairs\n",
    "                chair_count = sum(\n",
    "                    1 for box in results[0].boxes \n",
    "                    if int(box.cls[0]) == target_class_index\n",
    "                )\n",
    "                \n",
    "                # Annotate frame with detections\n",
    "                annotated_frame = results[0].plot()\n",
    "                \n",
    "                # Add text overlay for chair count\n",
    "                cv2.putText(\n",
    "                    annotated_frame, \n",
    "                    f\"# of chairs: {chair_count}\", \n",
    "                    (15, 70),  # Adjust position as needed\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1.0,  # Font scale \n",
    "                    (0, 255, 0),  # Green color \n",
    "                    3  # Thickness\n",
    "                )\n",
    "                \n",
    "                # Verify frame is correct\n",
    "                if annotated_frame is None:\n",
    "                    print(f\"WARNING: Could not annotate frame {frame_count}\")\n",
    "                    continue\n",
    "                \n",
    "                # Write frame\n",
    "                video_writer.write(annotated_frame)\n",
    "                \n",
    "                # Optional: Show progress\n",
    "                if frame_count % 30 == 0:\n",
    "                    print(f\"Processed frame {frame_count}\")\n",
    "                \n",
    "                processed_results.append({\n",
    "                    'frame': frame_count,\n",
    "                    'chair_count': chair_count\n",
    "                })\n",
    "            \n",
    "            # Release resources\n",
    "            input_video.release()\n",
    "            video_writer.release()\n",
    "            \n",
    "            print(f\"Video saved to: {output_video_path}\")\n",
    "            print(f\"Total frames processed: {frame_count}\")\n",
    "            \n",
    "            return processed_results\n",
    "        \n",
    "        # Image processing logic (unchanged from previous version)\n",
    "        else:\n",
    "            results = model.predict(\n",
    "                source=source,\n",
    "                conf=conf_threshold,\n",
    "                iou=iou_threshold,\n",
    "                save=False\n",
    "            )\n",
    "            \n",
    "            processed_results = []\n",
    "            results_csv_path = os.path.join(output_dirs['detection_results'], 'chair_counts.csv')\n",
    "            \n",
    "            with open(results_csv_path, 'w') as csv_file:\n",
    "                csv_file.write(\"Image,Chair Count,Annotated Image Path\\n\")\n",
    "                \n",
    "                for result in results:\n",
    "                    # Count chairs\n",
    "                    chair_count = sum(\n",
    "                        1 for box in result.boxes \n",
    "                        if int(box.cls[0]) == target_class_index\n",
    "                    )\n",
    "                    \n",
    "                    # Annotate image\n",
    "                    annotated_img = result.plot()\n",
    "                    \n",
    "                    # Add text for chair count\n",
    "                    cv2.putText(\n",
    "                        annotated_img, \n",
    "                        f\"# of chairs: {chair_count}\", \n",
    "                        (25, 160),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        5, \n",
    "                        (0, 255, 0), \n",
    "                        13\n",
    "                    )\n",
    "                    \n",
    "                    # Save original prediction\n",
    "                    pred_filename = f\"pred_{os.path.basename(result.path)}\"\n",
    "                    pred_path = os.path.join(output_dirs['predictions'], pred_filename)\n",
    "                    cv2.imwrite(pred_path, result.orig_img)\n",
    "                    \n",
    "                    # Save annotated image\n",
    "                    annotated_filename = f\"chairs_{os.path.basename(result.path)}\"\n",
    "                    annotated_path = os.path.join(output_dirs['annotated_images'], annotated_filename)\n",
    "                    cv2.imwrite(annotated_path, annotated_img)\n",
    "                    \n",
    "                    # Log to CSV\n",
    "                    csv_file.write(f\"{result.path},{chair_count},{annotated_path}\\n\")\n",
    "                    \n",
    "                    # Log detection\n",
    "                    logging.info(\n",
    "                        f\"Image: {result.path}, \"\n",
    "                        f\"Chairs Detected: {chair_count}\"\n",
    "                    )\n",
    "                    \n",
    "                    processed_results.append({\n",
    "                        'image_path': result.path,\n",
    "                        'chair_count': chair_count,\n",
    "                        'original_pred_path': pred_path,\n",
    "                        'annotated_path': annotated_path\n",
    "                    })\n",
    "            \n",
    "            return processed_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Detection error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Paths configuration\n",
    "        data_yaml_path = \"Augmented_Dataset/data.yaml\"\n",
    "        best_model_path = \"train_results/train/weights/best.pt\"\n",
    "        \n",
    "        # Create output directories\n",
    "        output_dirs = create_output_directories('.')\n",
    "        \n",
    "        # Setup logging\n",
    "        setup_logging(output_dirs['logs'])\n",
    "        \n",
    "        # Load model configuration\n",
    "        config = load_model_configuration(data_yaml_path)\n",
    "        \n",
    "        # Detect chairs (works for both images and video)\n",
    "        results = detect_chairs(\n",
    "            model_path=best_model_path,\n",
    "            source='Augmented_Dataset/test/images',  # Replace with your video/image path\n",
    "            output_dirs=output_dirs,\n",
    "            data_yaml_path=data_yaml_path,\n",
    "            conf_threshold=0.25,     # Slightly adjustable\n",
    "            iou_threshold=0.45\n",
    "        )\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"Total Items Processed: {len(results)}\")\n",
    "        print(f\"Outputs organized in: {output_dirs['root']}\")\n",
    "        print(f\"Detailed results logged in {os.path.join(output_dirs['logs'], 'chair_detection.log')}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Main process error: {e}\")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
