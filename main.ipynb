{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.47 üöÄ Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce 840M, 4038MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=dataset/data.yaml, epochs=5, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
      "‚ö†Ô∏è Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/mohammad/Desktop/Computer-Vision-24/Project/dataset/labels/train... 280 images, 7 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280/280 [00:00<00:00, 1067.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/mohammad/Desktop/Computer-Vision-24/Project/dataset/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/mohammad/Desktop/Computer-Vision-24/Project/dataset/labels/valid... 80 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:00<00:00, 827.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/mohammad/Desktop/Computer-Vision-24/Project/dataset/labels/valid.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      2.54G       2.67       3.35      2.558         49        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:26<00:00,  4.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232    0.00363      0.375    0.00866    0.00283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.54G       2.53      3.292      2.424         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:15<00:00,  4.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232    0.00387      0.401     0.0168    0.00701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.54G      2.509        3.2      2.418         46        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:09<00:00,  3.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232    0.00375      0.388     0.0174     0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.54G      2.484       3.18      2.379         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:24<00:00,  4.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232     0.0332      0.116     0.0196     0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.54G      2.455      3.136      2.347         63        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:19<00:00,  4.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232      0.175     0.0172     0.0265    0.00826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.118 hours.\n",
      "Optimizer stripped from /home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2/weights/best.pt...\n",
      "Ultralytics 8.3.47 üöÄ Python-3.12.3 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce 840M, 4038MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:11<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        232       0.28     0.0419     0.0374     0.0096\n",
      "Speed: 1.9ms preprocess, 135.1ms inference, 0.0ms loss, 7.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/mohammad/Desktop/Computer-Vision-24/runs/detect/train2\u001b[0m\n",
      "Training metrics are not available for plotting.\n",
      "Training complete. Best model saved at chair_detection/yolov8_chair/weights/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 63.8ms\n",
      "Speed: 6.8ms preprocess, 63.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   2%|‚ñé         | 1/40 [00:00<00:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 56.5ms\n",
      "Speed: 6.1ms preprocess, 56.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   5%|‚ñå         | 2/40 [00:00<00:13,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.2ms\n",
      "Speed: 12.7ms preprocess, 53.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   8%|‚ñä         | 3/40 [00:00<00:10,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.7ms\n",
      "Speed: 7.0ms preprocess, 52.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  10%|‚ñà         | 4/40 [00:01<00:08,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.3ms\n",
      "Speed: 13.9ms preprocess, 50.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  12%|‚ñà‚ñé        | 5/40 [00:01<00:08,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 10.4ms preprocess, 52.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  15%|‚ñà‚ñå        | 6/40 [00:01<00:07,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 7.4ms preprocess, 52.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  18%|‚ñà‚ñä        | 7/40 [00:01<00:06,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 62.6ms\n",
      "Speed: 6.3ms preprocess, 62.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  20%|‚ñà‚ñà        | 8/40 [00:01<00:06,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 9.4ms preprocess, 53.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  22%|‚ñà‚ñà‚ñé       | 9/40 [00:02<00:06,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.5ms\n",
      "Speed: 7.9ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  25%|‚ñà‚ñà‚ñå       | 10/40 [00:02<00:05,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.5ms\n",
      "Speed: 8.5ms preprocess, 54.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  28%|‚ñà‚ñà‚ñä       | 11/40 [00:02<00:05,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 59.0ms\n",
      "Speed: 11.3ms preprocess, 59.0ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  30%|‚ñà‚ñà‚ñà       | 12/40 [00:02<00:05,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 61.3ms\n",
      "Speed: 7.4ms preprocess, 61.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  32%|‚ñà‚ñà‚ñà‚ñé      | 13/40 [00:02<00:04,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 42.5ms\n",
      "Speed: 5.7ms preprocess, 42.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  35%|‚ñà‚ñà‚ñà‚ñå      | 14/40 [00:02<00:04,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 47.6ms\n",
      "Speed: 9.4ms preprocess, 47.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [00:03<00:05,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 60.0ms\n",
      "Speed: 8.4ms preprocess, 60.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:03<00:04,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 60.9ms\n",
      "Speed: 4.8ms preprocess, 60.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:03<00:04,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 46.0ms\n",
      "Speed: 8.0ms preprocess, 46.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [00:03<00:03,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.8ms\n",
      "Speed: 6.5ms preprocess, 52.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [00:03<00:03,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 61.0ms\n",
      "Speed: 5.4ms preprocess, 61.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [00:04<00:03,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 60.8ms\n",
      "Speed: 5.0ms preprocess, 60.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:04<00:03,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.4ms\n",
      "Speed: 6.1ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 22/40 [00:04<00:03,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.1ms\n",
      "Speed: 9.5ms preprocess, 52.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 23/40 [00:04<00:02,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.2ms\n",
      "Speed: 8.3ms preprocess, 50.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [00:04<00:03,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.9ms\n",
      "Speed: 12.3ms preprocess, 52.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:05<00:02,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 60.3ms\n",
      "Speed: 6.5ms preprocess, 60.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 26/40 [00:05<00:02,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 57.7ms\n",
      "Speed: 6.3ms preprocess, 57.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 27/40 [00:05<00:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 61.0ms\n",
      "Speed: 6.5ms preprocess, 61.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 28/40 [00:05<00:02,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 6.5ms preprocess, 54.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 29/40 [00:05<00:01,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.9ms\n",
      "Speed: 7.3ms preprocess, 52.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 30/40 [00:05<00:01,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 5.6ms preprocess, 52.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 31/40 [00:06<00:01,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 42.2ms\n",
      "Speed: 11.2ms preprocess, 42.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 32/40 [00:06<00:01,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.1ms\n",
      "Speed: 6.5ms preprocess, 54.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 33/40 [00:06<00:01,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 56.4ms\n",
      "Speed: 9.3ms preprocess, 56.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 34/40 [00:06<00:01,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 42.9ms\n",
      "Speed: 9.0ms preprocess, 42.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [00:07<00:01,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.9ms\n",
      "Speed: 7.8ms preprocess, 50.9ms inference, 7.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 36/40 [00:07<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 49.7ms\n",
      "Speed: 11.0ms preprocess, 49.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 37/40 [00:07<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.9ms\n",
      "Speed: 6.9ms preprocess, 52.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 38/40 [00:07<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 48.4ms\n",
      "Speed: 10.6ms preprocess, 48.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 39/40 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 55.9ms\n",
      "Speed: 6.1ms preprocess, 55.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:08<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to detected/results_summary.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 65.9ms\n",
      "Speed: 7.6ms preprocess, 65.9ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   2%|‚ñé         | 1/40 [00:00<00:25,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 45.1ms\n",
      "Speed: 8.5ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   5%|‚ñå         | 2/40 [00:01<00:23,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 5.1ms preprocess, 52.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:   8%|‚ñä         | 3/40 [00:01<00:23,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.9ms\n",
      "Speed: 5.9ms preprocess, 52.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  10%|‚ñà         | 4/40 [00:02<00:22,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.6ms\n",
      "Speed: 10.2ms preprocess, 52.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  12%|‚ñà‚ñé        | 5/40 [00:03<00:21,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 55.8ms\n",
      "Speed: 8.0ms preprocess, 55.8ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  15%|‚ñà‚ñå        | 6/40 [00:03<00:20,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.4ms\n",
      "Speed: 6.8ms preprocess, 50.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  18%|‚ñà‚ñä        | 7/40 [00:04<00:20,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 48.1ms\n",
      "Speed: 8.9ms preprocess, 48.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  20%|‚ñà‚ñà        | 8/40 [00:05<00:20,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 49.3ms\n",
      "Speed: 5.9ms preprocess, 49.3ms inference, 7.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  22%|‚ñà‚ñà‚ñé       | 9/40 [00:05<00:19,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 4.6ms preprocess, 52.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  25%|‚ñà‚ñà‚ñå       | 10/40 [00:06<00:18,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.4ms\n",
      "Speed: 5.5ms preprocess, 52.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  28%|‚ñà‚ñà‚ñä       | 11/40 [00:06<00:17,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 45.2ms\n",
      "Speed: 8.8ms preprocess, 45.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  30%|‚ñà‚ñà‚ñà       | 12/40 [00:07<00:17,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.4ms\n",
      "Speed: 4.7ms preprocess, 54.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  32%|‚ñà‚ñà‚ñà‚ñé      | 13/40 [00:08<00:16,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.4ms\n",
      "Speed: 9.6ms preprocess, 50.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  35%|‚ñà‚ñà‚ñà‚ñå      | 14/40 [00:08<00:15,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 59.7ms\n",
      "Speed: 6.3ms preprocess, 59.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [00:09<00:15,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 57.2ms\n",
      "Speed: 6.4ms preprocess, 57.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:09<00:14,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 48.2ms\n",
      "Speed: 5.9ms preprocess, 48.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:10<00:14,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 59.4ms\n",
      "Speed: 5.3ms preprocess, 59.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [00:11<00:13,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 59.9ms\n",
      "Speed: 9.5ms preprocess, 59.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [00:11<00:12,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.3ms\n",
      "Speed: 9.1ms preprocess, 53.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [00:12<00:12,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 7.5ms preprocess, 52.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:13<00:11,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 59.6ms\n",
      "Speed: 9.3ms preprocess, 59.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 22/40 [00:13<00:11,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 48.7ms\n",
      "Speed: 4.6ms preprocess, 48.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 23/40 [00:14<00:10,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 42.4ms\n",
      "Speed: 7.6ms preprocess, 42.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [00:14<00:09,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 56.3ms\n",
      "Speed: 6.6ms preprocess, 56.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:15<00:09,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 58.9ms\n",
      "Speed: 4.7ms preprocess, 58.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 26/40 [00:16<00:08,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.8ms\n",
      "Speed: 5.3ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 27/40 [00:16<00:08,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.5ms\n",
      "Speed: 5.9ms preprocess, 51.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 28/40 [00:17<00:07,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.0ms\n",
      "Speed: 5.6ms preprocess, 52.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 29/40 [00:17<00:06,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 4.8ms preprocess, 52.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 30/40 [00:18<00:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.1ms\n",
      "Speed: 6.0ms preprocess, 51.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 31/40 [00:19<00:05,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.9ms\n",
      "Speed: 8.1ms preprocess, 54.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 32/40 [00:19<00:04,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 61.3ms\n",
      "Speed: 4.9ms preprocess, 61.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 33/40 [00:20<00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.0ms\n",
      "Speed: 8.1ms preprocess, 51.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 34/40 [00:20<00:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 46.7ms\n",
      "Speed: 4.7ms preprocess, 46.7ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [00:21<00:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.8ms\n",
      "Speed: 6.4ms preprocess, 50.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 36/40 [00:22<00:02,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 43.2ms\n",
      "Speed: 7.1ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 37/40 [00:22<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.2ms\n",
      "Speed: 6.1ms preprocess, 52.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 38/40 [00:23<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 46.6ms\n",
      "Speed: 9.2ms preprocess, 46.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 39/40 [00:24<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.9ms\n",
      "Speed: 5.8ms preprocess, 50.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Live Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:24<00:00,  1.62it/s]\n",
      "Creating Video:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.9ms\n",
      "Speed: 8.3ms preprocess, 50.9ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:   2%|‚ñé         | 1/40 [00:00<00:13,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 45.8ms\n",
      "Speed: 7.8ms preprocess, 45.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:   5%|‚ñå         | 2/40 [00:00<00:16,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.8ms\n",
      "Speed: 14.4ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:   8%|‚ñä         | 3/40 [00:01<00:14,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 9.8ms preprocess, 53.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  10%|‚ñà         | 4/40 [00:01<00:12,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.0ms\n",
      "Speed: 10.5ms preprocess, 51.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  12%|‚ñà‚ñé        | 5/40 [00:01<00:10,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.9ms\n",
      "Speed: 8.8ms preprocess, 51.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  15%|‚ñà‚ñå        | 6/40 [00:01<00:09,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 49.3ms\n",
      "Speed: 6.3ms preprocess, 49.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  18%|‚ñà‚ñä        | 7/40 [00:02<00:09,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 42.4ms\n",
      "Speed: 5.5ms preprocess, 42.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  20%|‚ñà‚ñà        | 8/40 [00:02<00:09,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 59.0ms\n",
      "Speed: 7.4ms preprocess, 59.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  22%|‚ñà‚ñà‚ñé       | 9/40 [00:02<00:09,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.9ms\n",
      "Speed: 4.7ms preprocess, 53.9ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  25%|‚ñà‚ñà‚ñå       | 10/40 [00:03<00:08,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.5ms\n",
      "Speed: 5.9ms preprocess, 54.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  28%|‚ñà‚ñà‚ñä       | 11/40 [00:03<00:07,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.0ms\n",
      "Speed: 7.6ms preprocess, 54.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  30%|‚ñà‚ñà‚ñà       | 12/40 [00:03<00:07,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 60.6ms\n",
      "Speed: 4.7ms preprocess, 60.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  32%|‚ñà‚ñà‚ñà‚ñé      | 13/40 [00:03<00:06,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.7ms\n",
      "Speed: 4.9ms preprocess, 53.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  35%|‚ñà‚ñà‚ñà‚ñå      | 14/40 [00:03<00:06,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.4ms\n",
      "Speed: 5.8ms preprocess, 54.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [00:04<00:06,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.9ms\n",
      "Speed: 8.9ms preprocess, 51.9ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:04<00:06,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 60.9ms\n",
      "Speed: 6.0ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:04<00:05,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.4ms\n",
      "Speed: 8.4ms preprocess, 50.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [00:05<00:05,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.4ms\n",
      "Speed: 4.4ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [00:05<00:05,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 47.8ms\n",
      "Speed: 5.8ms preprocess, 47.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [00:05<00:04,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 62.5ms\n",
      "Speed: 9.2ms preprocess, 62.5ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:05<00:04,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 44.1ms\n",
      "Speed: 7.1ms preprocess, 44.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 22/40 [00:06<00:04,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.6ms\n",
      "Speed: 8.0ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 23/40 [00:06<00:04,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.9ms\n",
      "Speed: 6.7ms preprocess, 50.9ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [00:06<00:04,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 51.0ms\n",
      "Speed: 7.2ms preprocess, 51.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:06<00:04,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.3ms\n",
      "Speed: 7.5ms preprocess, 54.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 26/40 [00:07<00:04,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.5ms\n",
      "Speed: 4.6ms preprocess, 52.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 27/40 [00:07<00:03,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 54.4ms\n",
      "Speed: 6.7ms preprocess, 54.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 28/40 [00:07<00:03,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 52.3ms\n",
      "Speed: 8.5ms preprocess, 52.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 29/40 [00:07<00:02,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 48.9ms\n",
      "Speed: 6.0ms preprocess, 48.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 30/40 [00:08<00:02,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.3ms\n",
      "Speed: 5.2ms preprocess, 50.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 31/40 [00:08<00:02,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.0ms\n",
      "Speed: 6.4ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 32/40 [00:08<00:02,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 50.3ms\n",
      "Speed: 10.8ms preprocess, 50.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 33/40 [00:09<00:01,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 56.7ms\n",
      "Speed: 5.8ms preprocess, 56.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 34/40 [00:09<00:01,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 43.7ms\n",
      "Speed: 9.6ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [00:09<00:01,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 48.0ms\n",
      "Speed: 8.4ms preprocess, 48.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 36/40 [00:09<00:01,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 58.0ms\n",
      "Speed: 4.7ms preprocess, 58.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 37/40 [00:10<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 53.4ms\n",
      "Speed: 8.2ms preprocess, 53.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 38/40 [00:10<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 63.5ms\n",
      "Speed: 6.7ms preprocess, 63.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 39/40 [00:10<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 61.1ms\n",
      "Speed: 4.9ms preprocess, 61.1ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Video: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:11<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at detections_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Ensure Dataset Path Exists\n",
    "dataset_path = \"dataset/data.yaml\"  # Update with your dataset path\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset YAML file not found: {dataset_path}\")\n",
    "\n",
    "# Load Pretrained YOLOv8 Model\n",
    "model = YOLO('yolov8n.pt')  # Use 'yolov8n.pt', 'yolov8s.pt', etc., based on your hardware capacity\n",
    "\n",
    "# Train the Model\n",
    "results = model.train(\n",
    "    data=dataset_path,       # Path to dataset YAML\n",
    "    epochs=5,                # Number of epochs\n",
    "    batch=16,                # Batch size\n",
    "    imgsz=640,               # Image size\n",
    "    workers=4,               # Number of data loading workers\n",
    "    optimizer='AdamW',       # Optimizer\n",
    "    lr0=0.001,               # Initial learning rate\n",
    "    patience=10,             # Early stopping\n",
    "    augment=True,            # Data augmentation\n",
    "    val=True                 # Validate after each epoch\n",
    ")\n",
    "\n",
    "# Plot Training Loss\n",
    "if hasattr(results, 'metrics'):\n",
    "    metrics = results.metrics\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(metrics.get('box_loss', []), label=\"Box Loss\")\n",
    "    plt.plot(metrics.get('obj_loss', []), label=\"Object Loss\")\n",
    "    plt.plot(metrics.get('cls_loss', []), label=\"Classification Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Training metrics are not available for plotting.\")\n",
    "\n",
    "# Save the Best Model\n",
    "best_model_path = 'chair_detection/yolov8_chair/weights/best.pt'\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "model.save(best_model_path)\n",
    "print(f\"Training complete. Best model saved at {best_model_path}\")\n",
    "\n",
    "# Load Trained Model\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# Function to Detect and Count Objects\n",
    "def detect_and_count(image, model, class_name=\"chair\"):\n",
    "    results = model(image)  # Run detection\n",
    "    detections = results[0].boxes  # Extract bounding boxes\n",
    "    chair_count = 0\n",
    "\n",
    "    # Process each detection\n",
    "    for detection in detections:\n",
    "        class_id = int(detection.cls)  # Class ID\n",
    "        if model.names[class_id] == class_name:  # Match the target class\n",
    "            chair_count += 1\n",
    "            # Draw bounding box and label\n",
    "            x1, y1, x2, y2 = map(int, detection.xyxy[0])  # Bounding box coordinates\n",
    "            conf = detection.conf  # Confidence score\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                f\"{class_name} {conf:.2f}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 255, 0),\n",
    "                2,\n",
    "            )\n",
    "    return image, chair_count\n",
    "\n",
    "# Process Images and Save Results\n",
    "def process_images(input_dir, output_dir, model, class_name=\"chair\"):\n",
    "    results_summary = []\n",
    "    supported_formats = (\".jpg\", \".png\", \".jpeg\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in tqdm(os.listdir(input_dir), desc=\"Processing images\"):\n",
    "        if not img_file.endswith(supported_formats):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        try:\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(\"Invalid image format or file.\")\n",
    "\n",
    "            annotated_image, count = detect_and_count(image, model, class_name)\n",
    "            output_path = os.path.join(output_dir, img_file)\n",
    "            cv2.imwrite(output_path, annotated_image)\n",
    "            results_summary.append({\"image\": img_file, \"chair_count\": count})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "    summary_path = os.path.join(output_dir, \"results_summary.json\")\n",
    "    with open(summary_path, \"w\") as json_file:\n",
    "        json.dump(results_summary, json_file, indent=4)\n",
    "\n",
    "    print(f\"Processing complete. Results saved to {summary_path}\")\n",
    "\n",
    "# Live Detection Display\n",
    "def live_detection(input_dir, model, class_name=\"chair\"):\n",
    "    supported_formats = (\".jpg\", \".png\", \".jpeg\")\n",
    "    window_name = \"Live Detection Results\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, 800, 600)\n",
    "\n",
    "    for img_file in tqdm(os.listdir(input_dir), desc=\"Live Detection\"):\n",
    "        if not img_file.endswith(supported_formats):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(input_dir, img_file)\n",
    "        try:\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(\"Invalid image format or file.\")\n",
    "\n",
    "            annotated_image, count = detect_and_count(image, model, class_name)\n",
    "            cv2.imshow(window_name, annotated_image)\n",
    "            if cv2.waitKey(500) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Save Detections as Video\n",
    "def save_detection_video(input_dir, output_video_path, model, class_name=\"chair\"):\n",
    "    supported_formats = (\".jpg\", \".png\", \".jpeg\")\n",
    "    frame_rate = 10  # Adjust frame rate as needed\n",
    "\n",
    "    # Validate input images\n",
    "    valid_images = [\n",
    "        os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(supported_formats)\n",
    "    ]\n",
    "    if not valid_images:\n",
    "        raise ValueError(\"No valid image files found in the directory.\")\n",
    "\n",
    "    # Determine frame size\n",
    "    first_frame = cv2.imread(valid_images[0])\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    # Define video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    for img_file in tqdm(valid_images, desc=\"Creating Video\"):\n",
    "        try:\n",
    "            image = cv2.imread(img_file)\n",
    "            annotated_image, count = detect_and_count(image, model, class_name)\n",
    "            video_writer.write(annotated_image)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n",
    "\n",
    "    video_writer.release()\n",
    "    print(f\"Video saved at {output_video_path}\")\n",
    "\n",
    "# Input and Output Directories\n",
    "INPUT_IMAGES_DIR = \"dataset/images/test\"  # Replace with your image directory\n",
    "OUTPUT_IMAGES_DIR = \"detected\"  # Replace with output directory\n",
    "os.makedirs(OUTPUT_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# Process and Save Annotated Images\n",
    "process_images(INPUT_IMAGES_DIR, OUTPUT_IMAGES_DIR, model)\n",
    "\n",
    "# Live Detection Display\n",
    "live_detection(INPUT_IMAGES_DIR, model)\n",
    "\n",
    "# Save Detection Results as Video\n",
    "save_detection_video(INPUT_IMAGES_DIR, \"detections_output.mp4\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
